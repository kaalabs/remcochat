version = 2

[app]
default_provider_id = "vercel"

[app.router]
enabled = true
provider_id = "vercel"
model_id = "openai/gpt-4o-mini"
min_confidence = 0.7
max_input_chars = 600

[app.web_tools]
enabled = true
max_results = 8
recency = "week"
allowed_domains = []
blocked_domains = []

# Attachments (documents only) are enabled by default.
# Document extraction runs in Vercel Sandbox. If sandbox credentials are missing,
# attachment uploads still work but extraction will fail at send-time.
[app.attachments]
enabled = true
allowed_media_types = [
  "text/plain",
  "text/markdown",
  "text/csv",
  "application/json",
  "application/pdf",
]
max_files_per_message = 3
max_file_size_bytes = 2000000
max_total_size_bytes = 5000000
max_extracted_text_chars = 120000
temporary_ttl_ms = 21600000 # 6 hours

[app.attachments.sandbox]
runtime = "node22"
vcpus = 2
timeout_ms = 900000

[app.attachments.processing]
timeout_ms = 30000
max_stdout_chars = 200000
max_stderr_chars = 20000

# Bash tools (Vercel Sandbox) are disabled by default.
# Enabling them requires BOTH:
# - config: app.bash_tools.enabled = true
# - env: REMCOCHAT_ENABLE_BASH_TOOL=1
# If access="lan", also set REMCOCHAT_ADMIN_TOKEN and send it on every /api/chat request
# via x-remcochat-admin-token or Authorization: Bearer.
[app.bash_tools]
enabled = false
provider = "vercel"  # "vercel" | "docker"
access = "localhost" # "localhost" | "lan"
project_root = ""    # required if seed.mode="upload"
max_stdout_chars = 12000
max_stderr_chars = 12000
timeout_ms = 30000
max_concurrent_sandboxes = 2
idle_ttl_ms = 900000 # 15 minutes

[app.bash_tools.sandbox]
runtime = "node22" # vercel: "node22" | "python3.13"; docker: "node24" | "python3.13"
ports = [3000] # Vercel: exposed as public URLs; Docker: published via sandboxd (max 4). Use [] to disable.
vcpus = 2
timeout_ms = 900000

[app.bash_tools.docker]
orchestrator_url = "" # required when provider="docker" (e.g. "http://127.0.0.1:8080")
admin_token_env = "REMCOCHAT_ADMIN_TOKEN" # env var to use for sandboxd auth
network_mode = "default" # "default" (egress allowed) | "none"
memory_mb = 2048

[app.bash_tools.seed]
mode = "git"         # "git" | "upload"
git_url = ""         # required if mode="git"
git_revision = ""    # optional
upload_include = "**/*" # used only for mode="upload"

# Providers configure only:
# - how to connect (base_url + api_key_env)
# - which models are allowed (allowed_model_ids + default_model_id)
# Everything else (labels/capabilities/types/limits/modalities) is resolved at runtime
# via the `modelsdev` CLI and stored in-memory until server restart.

[providers.vercel]
name = "Vercel AI Gateway"
api_key_env = "VERCEL_AI_GATEWAY_API_KEY"
base_url = "https://ai-gateway.vercel.sh/v3/ai"
modelsdev_provider_id = "vercel"
default_model_id = "openai/gpt-5.2-chat"
allowed_model_ids = [
  "openai/gpt-5.2-chat",
  "openai/gpt-4o-mini",
  "openai/gpt-5.2-pro",
  "openai/gpt-5.2-codex",
  "anthropic/claude-opus-4.5",
]

[providers.opencode]
name = "OpenCode Zen"
api_key_env = "OPENCODE_API_KEY"
base_url = "https://opencode.ai/zen/v1"
modelsdev_provider_id = "opencode"
default_model_id = "gpt-5-nano"
allowed_model_ids = [
  "gpt-5-nano",
  "gpt-5.2-codex",
  "claude-opus-4-5",
  "glm-4.7-free",
  "kimi-k2",
]
